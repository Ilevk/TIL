{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2주차, 1일차 : 표현(Representation)에 대해 이해하기 (총 60분)\n",
    "\n",
    "- ### Contents \n",
    "    1. Representation : https://developers.google.com/machine-learning/crash-course/representation/video-lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Representation : Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원시 데이터를 특성에 매핑 \n",
    "- 그림의 왼쪽은 원시 데이터이고 오른쪽 부분은 특성 벡터이다. \n",
    "- 여러 머신러닝 모델은 특성 값에 모델 가중치를 곱해야 하므로 실수 벡터로 가중치를 표현해야한다.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/RawDataToFeatureVector.svg />\n",
    "<b>Figure 1. 특성 추출을 통해 원시 데이터를 ML 특성에 매핑</b>\n",
    "\n",
    "### 숫자 값 매핑\n",
    "- 다음과 같은 정수와 부동 소수점 데이터에는 숫자 가중치를 곱할 수 있으므로 특수한 인코딩이 필요없다.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/FloatingPointFeatures.svg />\n",
    "<b>Figure 2. 정수 값을 부동 소수점 값에 매핑</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 범주 값 매핑\n",
    "- 범주형 특성은 가능한 값의 이산 집합을 갖는다. 이러한 경우 모델은 학습된 가중치로 문자열을 곱할 수 없으므로 특성 추출을 통해 문자열을 숫자열로 변환한다.\n",
    "    1. Out of vocabulary : 0, 1, 2, 3.. 으로 매핑, 라벨 인코딩\n",
    "    2. One-hot Encoding : 단일 값이 1이고 다른 요소는 모두 0으로 설정, 원핫 인코딩\n",
    "    \n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/OneHotEncoding.svg />\n",
    "<b>원-핫 인코딩을 통한 거리 주소 매핑</b>\n",
    "\n",
    "- 원 핫 인코딩은 모든 특성 값에 대한 부울 변수를 효과적으로 만들 수 있음. \n",
    "\n",
    "### 희소 표현\n",
    "- 데이터 셋에 특정 컬럼에 대해서 값으로 포함하고자 하는 범주가 백만개 있다면, 1개 또는 2개 요소만 true인 요소 백만개의 바이너리 벡터를 명시적으로 만드는 것은 매우 비효율 적인 표현이다. 이러한 상황에서 일반적인 방식은 0이 아닌 값만 저장하는 희소 표현을 사용한다. \n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Representation : Qualities of Good Features\n",
    "- 이번에는 특성 벡터 내에서 어떠한 종류의 값이 실제로 좋은 특성인지 알아본다.\n",
    "\n",
    "### 거의 사용되지 않는 불연속 특성 값 제거\n",
    "- 좋은 특성 값은 데이터 셋에서 5회 이상 나타나야한다. 이러한 특성 값은 모델에서 라벨과의 관계를 학습하기 쉽다. \n",
    "- 반대로, 특성의 값이 한 번만 나타나거나 매우 드물게 나타난다면 모델에서 해당 특성을 기반으로 예측할 수 없다. \n",
    "\n",
    "### 가급적 분명하고 명확한 의미 부여\n",
    "- 각 특성은 명확하고 분명한 의미를 가져야한다. ex) 집의 연식 : 27\n",
    "- 반대로, 다음 특성 값은 특성을 만든 엔지니어 이외에 다른 사람은 알아보기 어렵다. ex) 집의 연식 : 851472000 \n",
    "- 엔지니어링 측면의 실수와 관계없이 데이터의 노이즈로 인해 값이 불명확해지는 경우도 있다. ex) 사용자의 나이 : 277\n",
    "\n",
    "### '특수'값을 실제 데이터와 혼용하지 말 것\n",
    "- 좋은 특성은 특이한 범위 외에 불연속성 또는 '특수'값을 포함하지 않습니다. 예를 들어 어떤 특성의 값이 0~1 범위이고, 입력하지 않은 데이터의 경우에 -1을 부여한다고 하면 해당 값은 특수 값이 된다.\n",
    "\n",
    "### 업스트림 불안정성 고려\n",
    "- 특성의 정의는 시간이 지나도 변하지 않아야 한다. 예를 들어 도시의 이름은 일반적으로 바뀌지 않으므로 유용한 값이 될 수 있다. 그러나 다른 모델에서 추론한 값을 수집할 때에는 문제점이 있다. 어떤 도시의 값이 현재 '219'라고 할 때, 다른 모델을 이후에 실행하면 '219'가 아닐 수 있다.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Representation : Cleaning Data\n",
    "- 한 그루의 사과나무에선느 좋은 사과와 벌레 먹은 사과가 같이 열립니다. 그러나 과일 가게에서 판매하는 과일들은 모두 최고의 품질을 자랑합니다. 누군가 불량한 과일을 솎아내고 흠집이 있는 과일을 깨끗이 손질한 것이다. \n",
    "- ML 엔지니어 역시 불량한 예를 솎아내고 약간의 문제가 있는 예를 손질하는 데 막대한 노력을 기울여야 합니다.\n",
    "\n",
    "### 특성 값 조정\n",
    "- `조정`이란 부동 소수점 특성 값을 100\\~900 등의 자연 범위에서 0\\~1 또는 -1\\~+1 등의 표준 범위로 변환하는 작업이다. \n",
    "- 특성 셋이 단일 특성으로만 구성된 경우 조정에 따르는 실질적인 이점은 거의 없습니다.\n",
    "- 그러나 특성 세트가 여러 특성으로 구성되었다면 특성 조정으로 다음과 같은 이점을 누릴 수 있습니다.\n",
    "    - 경사하강법이 더 빠르게 수렴됩니다.\n",
    "    - 'NAN 트랩'이 방지됩니다. NAN 트랩이란 모델의 숫자 중 하나가 NaN이 된 후 수학 연산 과정에서 모델의 다른 모든 숫자가 결국 NaN이 되는 상황입니다.\n",
    "    - 모델이 각 특성의 적절한 가중치를 익히는데 도움이 됩니다. 특성 조정을 수행하지 않으면 모델에서 범위가 더 넓은 특성을 과도(민감)하게 중시합니다.\n",
    "    \n",
    "### 극단적 이상점 처리\n",
    "- 극단적인 이상치를 가지고 있는 특성은 치우친 분포를 보여줍니다. 시각화를 통해 이를 확인하고 조정으로 처리하겠습니다.\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/ScalingNoticingOutliers.svg />\n",
    "\n",
    "<b>Figure 4. 매우 긴 꼬리</b>\n",
    "\n",
    "- 이러한 극단적 이상점이 주는 영향을 최소화 하려면, 모든 값에 로그를 취하는 방법이 있습니다.\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/ScalingLogNormalization.svg />\n",
    "\n",
    "<b>Figure 5. 로그 조정을 거쳐도 꼬리가 남아있음 </b>\n",
    "\n",
    "- 로그 조정을 거치면 다소 개선되지만, 이상점 값의 꼬리가 아직도 상당히 남아있다. 이러한 경우 특성 값의 범위의 상한을 만들어 대체하는 방법을 사용할 수 있습니다. 상한보다 큰 값들을 상한 값으로 대체하면, 끝 부분이 부자연스러워질 수 있지만 기존의 이상치 보다는 유용한 상태입니다. \n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/ScalingClipping.svg />\n",
    "\n",
    "### 비닝 \n",
    "- 다음은 캘리포니아의 위도에 따른 상대적인 주택 분포를 보여주는 Plot 입니다. \n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/ScalingBinningPart1.svg />\n",
    "<b> Figure 7. 위도별 주택 수 </b>\n",
    "\n",
    "- 데이터 세트에서 `latitute`는 실수 값입니다. 그러나 이 모델에서 `latitude`를 실수 특성으로 표현할 수는 없는데, 이는 위도와 주택 값 사이에 선형적 관계가 없기 때문입니다. 위도를 유요한 예측 지표로 사용하기 위해 다음 그림과 같이 여러 빈(bin)으로 나누어 보겠습니다. \n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/ScalingBinningPart2.svg />\n",
    "<b>Figure 8. 값 비닝 </b>\n",
    "\n",
    "- 이제 실수 값 하나가 아니라 11개의 개별 특성이 생겼습니다. 11개의 개별 특성을 11원소 벡터로 통일하여 위도를 표현할 수 있습니다. 위도 37.4도를 다음과 같이 표현할 수 있습니다.  \n",
    "\n",
    "`[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]`\n",
    "\n",
    "### 스크러빙\n",
    "- 지금까지는 학습 및 테스트에 사용되는 모든 데이터를 신뢰할 수 있다고 가정했습니다. 그러나 실무에서는 다음과 같은 이유로 데이터 셋의 여러 예를 신뢰하기 어렵습니다.\n",
    "    - <b>값 누락</b>, 예를 들어 사용자가 주택의 연식을 실수로 입력하지 않았을 수 있습니다.\n",
    "    - <b>중복 예</b>, 예를 들어 서버에서 같은 로그를 실수로 두 번 업로드했을 수 있습니다.\n",
    "    - <b>잘못된 라벨</b>, 예를 들어 사용자가 참나무 사진에 실수로 단풍나무 라벨을 지정했을 수 있습니다.\n",
    "    - <b>잘못된 특성 값</b>, 예를 들어 사용자가 숫자를 실수로 입력했거나 온도계를 햇빛에 두었을 수 있습니다..\n",
    "\n",
    "- 잘못된 개별 데이터를 탐지하는 것 외에 집계에서도 잘못된 데이터를 탐지해야 합니다. 히스토그램은 집계 데이터를 시각화 하는 유용한 메커니즘 입니다. 또한, 다음과 같은 통계를 구하면 도움이 될 수 있습니다.\n",
    "    - 최대 및 최소\n",
    "    - 평균 및 중앙값\n",
    "    - 표준편차\n",
    "    \n",
    "### 철저한 데이터 파악\n",
    "- 정상적인 데이터가 어떠한 모습이어야 하는지 항상 생각하세요.\n",
    "- 데이터가 이러한 예상과 일치하는지 확인하고, 그렇지 않다면 그 이유를 파악해보세요.\n",
    "- 학습 데이터가 대시보드 등의 다른 소스와 일치하는지 재차 확인하세요.\n",
    "- 좋은 데이터가 좋은 ML 모델을 만듭니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kyle",
   "language": "python",
   "name": "kyle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
