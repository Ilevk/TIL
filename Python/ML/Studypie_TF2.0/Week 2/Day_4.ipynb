{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2주차, 3일차 : 분류 이해하기 (총 90분)\n",
    "- ### Contents \n",
    "    1. Classification: https://developers.google.com/machine-learning/crash-course/classification/video-lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification: Thresholding\n",
    "- 로지스틱 회귀는 확률을 반환합니다. 반환된 확률을 '있는 그대로' 사용하거나 이진 값으로 변환하여 사용할 수 있습니다.\n",
    "\n",
    "- 로지스틱 회귀 모형에서 특정 이메일에 관해 0.9995가 반환되면 이 이메일은 스팸일 가능성이 매우 높은 메일로 예측된 것입니다. 이와 반대로 0.0003점인 다른 이메일은 스팸이 아닐 가능성이 높습니다.\n",
    "- 그렇다면 0.6점인 이메일은 어떨까요? 확률 값을 이진 카테고리에 매핑하려면 분류 임계값을 정의해야 합니다. \n",
    "- 임계값보다 높은 값은 '스팸'을 나타내고 임계값보다 낮은 값은 '스팸 아님'을 나타냅니다. \n",
    "- 분류 임계값은 항상 0.5여야 한다고 생각하기 쉽지만 임계값은 문제에 따라 달라지므로 값을 조정해야합니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Classification: True vs. False; Positive vs. Negative\n",
    "- 양치기 소년에서 '늑대다'는 양성 클래스 입니다. '늑대가 없다'는 음성 클래스 입니다.\n",
    "\n",
    "'늑대 예측'모델에서 발생할 수 잇는 4가지 결과를 요약하면 다음과 같이 2x2 Confusion Matirx를 사용해 나타낼 수 있습니다.\n",
    "\n",
    "비고|참 Positive|참 Negative\n",
    "---|---|---\n",
    "예측 Positive|참 양성(TP)|허위 양성(FP)\n",
    "예측 Negative|허위 음성(FN)|참 음성(TN)\n",
    "\n",
    "- **참 양성**은 모델에서 Positive 클래스를 정확하게 평가하는 결과입니다. 마찬가지로 **참 음성**은 모델에서 Negative 클래스를 정확하게 평가하는 결과입니다.\n",
    "- **거짓 양성**은 모델에서 Positive 클래스를 잘못 예측한 결과입니다. **거짓 음성**은 모델에서 Negative 클래스를 잘못 예측한 결과입니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Classification: Accuracy\n",
    "- 정확성은 분류 모델 평가를 위한 측정항목 중 하나입니다. 비공식적으로 **정확성**은 모델의 예측이 얼마나 정확한가를 보여줍니다.\n",
    "\n",
    "$$정확성={{정확한\\ 예측\\ 수} \\over {총\\ 예측\\ 수}}$$\n",
    "\n",
    "- 이진 분류에서는 다음과 같이 양성과 음성을 기준으로 정확성을 계산할 수도 있습니다.\n",
    "\n",
    "$$정확성={{TP+TN} \\over {TP+TN+FP+FN}} $$\n",
    "\n",
    "- 다음과 같이 악성으로 분류된 종양(Positive Class) 또는 양성으로 분류된 종양(Negative Class) 모델 100개의 정확성을 계싼해 보겠습니다.\n",
    "\n",
    "비고|참 Positive|참 Negative\n",
    "---|---|---\n",
    "예측 Positive|참 양성(TP)<br>-실제:악성<br>-예측:악성<br>TP:1|허위 양성(FP)<br>-실제:양성<br>-예측:악성<br>FP:1\n",
    "예측 Negative|허위 음성(FN)<br>-실제:악성<br>-예측:양성<br>FN:8|참 음성(TN)<br>-실제:양성<br>-예측:양성<br>TP:90\n",
    "\n",
    "$$정확성={{TP+TN} \\over {TP+TN+FP+FN}}={{1+90} \\over {1+90+1+8}}=0.91$$\n",
    "\n",
    "- 정확성은 0.91 또는 91%로 나타냅니다. 이는 종양 분류자가 악성 종양을 제대로 식별했음을 의미합니다. \n",
    "- 언뜻 보기에는 91% 정확성이 좋아 보일 수 있지만, 이 예제에서 항상 양성으로 예측하는 다른 종양 분류자 모델도 정확히 동일한 정확성을 달성할 것입니다. (예측 능력이 0과 다를 바 없다.)\n",
    "- 이와 같이 **클래스 불균형 데이터 셋**을 사용하면 양성 라벨 수와 음성 라벨 수가 상당히 다르므로 정확성만으로는 모든 것을 평가할 수 없다.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Classification: Precision and Recall\n",
    "### 정밀도\n",
    "정밀도란?\n",
    "\n",
    "    양성으로 식별된 사례 중 실제로 양성이었던 사례의 비율, True라고 예측한 것 중에 실제로 True인 것\n",
    "\n",
    "$$정밀도={TP\\over{TP+FP}}$$\n",
    "\n",
    "비고|참 Positive|참 Negative\n",
    "---|---|---\n",
    "예측 Positive|참 양성(TP): 1|허위 양성(FP): 1\n",
    "예측 Negative|허위 음성(FN): 8|참 음성(TN): 90\n",
    "\n",
    "$$정밀도={TP\\over{TP+FP}}={1\\over{1+1}}=0.5$$\n",
    "- 이 모델의 정밀도는 0.5입니다. 즉, 이 모델에서 어떤 종양이 악성일 것이라고 평가했을 때, 이 평가가 정확할 확률은 50% 입니다.\n",
    "\n",
    "### 재현율\n",
    "재현율이란?\n",
    "\n",
    "    실제 양성 중 정확히 양성이라고 식별된 사례의 비율, 실제로 True인 것 중에 True라고 예측한 것\n",
    "    \n",
    "$$재현율={TP\\over{TP+FN}}$$\n",
    "\n",
    "$$정밀도={TP\\over{TP+FN}}={1\\over{1+8}}=0.11$$\n",
    "\n",
    "- 이 모델의 재현율은 0.11입니다. 즉, 이 모델에서는 모든 악성 종양 중 11%가 정확하게 식별됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정밀도 및 재현율: 줄다리기\n",
    "- 모델의 효과를 완전히 평가하려면 정밀도와 재현율을 모두 검사해야합니다. 그런데 정밀도와 재현율은 서로 상충하는 관계에 있는 경우가 많습니다. 즉, 정밀도가 향상되면 대개 재현율이 감소되고 반대의 경우도 마찬가지 입니다.\n",
    "\n",
    "\n",
    "- 문류 임계값 오른쪽에 있는 메일은 '스팸'으로 분류되는 반면 왼쪽에 있는 메일은 '스팸 아님'으로 분류됩니다.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/PrecisionVsRecallBase.svg style='background-color:white'/>\n",
    "<b>Figure 1. 스팸 또는 스팸 아님으로 이메일 분류하기 </b>\n",
    "\n",
    "비고|참 Positive|참 Negative\n",
    "---|---|---\n",
    "예측 Positive|참 양성(TP): 8|허위 양성(FP): 2\n",
    "예측 Negative|허위 음성(FN): 3|참 음성(TN): 17\n",
    "\n",
    "- 정말도는 정확하게 분류된 스팸으로 신고된 이메일의 비율, 스팸이라고 한 것 중에 실제로 스팸인 비율\n",
    "$$정밀도={TP\\over{TP+FN}}={2\\over{8+2}}=0.8$$\n",
    "\n",
    "- 재현율은 정확하게 분류된 실제 스팸 이메일의 비율, 실제로 스팸인 이메일 중에 스팸으로 예측된 것\n",
    "$$정밀도={TP\\over{TP+FN}}={8\\over{8+3}}=0.73$$\n",
    "\n",
    "- 그림 2는 분류 임계값 증가의 효과를 보여줍니다.\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/PrecisionVsRecallRaiseThreshold.svg style='background-color:white'/>\n",
    "<b>Figure 2. 분류 임계값 증가 </b>\n",
    "\n",
    "비고|참 Positive|참 Negative\n",
    "---|---|---\n",
    "예측 Positive|참 양성(TP): 7|허위 양성(FP): 1\n",
    "예측 Negative|허위 음성(FN): 4|참 음성(TN): 18\n",
    "\n",
    "$$정밀도={TP\\over{TP+FN}}={7\\over{7+1}}=0.88$$\n",
    "\n",
    "$$정밀도={TP\\over{TP+FN}}={7\\over{7+4}}=0.64$$\n",
    "\n",
    "- 반대로 그림 3은 그림 1의 원래 위치로부터 분류 임계값이 감소하는 효과를 보여줍니다.\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/PrecisionVsRecallLowerThreshold.svg style='background-color:white'/>\n",
    "<b>Figure 3. 분류 임계값 감소 </b>\n",
    "\n",
    "비고|참 Positive|참 Negative\n",
    "---|---|---\n",
    "예측 Positive|참 양성(TP): 9|허위 양성(FP): 3\n",
    "예측 Negative|허위 음성(FN): 2|참 음성(TN): 16\n",
    "\n",
    "$$정밀도={TP\\over{TP+FN}}={9\\over{9+3}}=0.75$$\n",
    "\n",
    "$$정밀도={TP\\over{TP+FN}}={9\\over{9+2}}=0.82$$\n",
    "\n",
    "- 정밀도와 재현율을 모두 사용하는 대표적인 측정 항목으로 F1 Score가 있습니다.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Classification: ROC Curve and AUC\n",
    "- ROC 곡선(수신자 조작 특성 곡선)은 모든 분류 임계값에서 분류 모델의 성능을 보여주는 그래프 입니다.\n",
    "    - 참 양성 비율(TPR)\n",
    "    - 허위 양성 비율(FPR)\n",
    "- **참 양성 비율(TPR)**은 재현율의 동의어이며 이에 따라 다음과 같이 정의됩니다.\n",
    "$$TPR={TP\\over{TP+FN}}$$\n",
    "- **허위 양성 비율(FPR)**은 다음과 같이 정의됩니다.\n",
    "$$FPR={FP\\over{FP+TN}$$\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/ROCCurve.svg style='background-color:white'/>\n",
    "<b> Figure 4. 다양한 분류 임계값의 참 양성(TP) 및 허위 양성(FP) 비율</b>\n",
    "\n",
    "### AUC: ROC 곡선 아래 영역\n",
    "- **AUC**는 'ROC 곡선 아래 영역'을 의미합니다. 즉, AUC는 (0,0)에서 (1,1)까지 전체 ROC 곡선 아래에 있는 전체 2차원 영역을 측정합니다.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/AUC.svg style='background-color:white'/>\n",
    "<b>Figure 5. AUC(ROC 곡선 아래 영역) </b>\n",
    "\n",
    "- AUC는 가능한 모든 분류 임계값에서 성능의 집계 측정 값을 제공합니다. \n",
    "\n",
    "- AUC는 다음 두 가지 이유로 이상적입니다\n",
    "    - AUC는 **척도 불변**입니다. 절대값이 아니라 예측이 얼마나 잘 평가되는지 측정합니다.\n",
    "    - AUC는 **분류 임계값 불변**입니다. 어떤 분류 임계값이 선택되었는지와 상관없이 모델의 예측 품질을 측정합니다.\n",
    "- 하지만 이러한 두 이유는 특정 사용 사례에서 AUC의 유용성을 제한할 수 있다는 단점이 있습니다.\n",
    "    - **척도 불변이 항상 이상적인 것은 아닙니다.** 예를 들어 잘 보정된 확률 결과가 필요한 경우에는 AUC로는 이 정보를 알 수 없습니다.\n",
    "    - **분류 임계값 불변이 항상 이상적인 것은 아닙니다** 허위 음성 비용과 허위 양성 비용에 큰 차이가 있는 경우 한 가지 유형의 분류 오류를 최소화 하는 것은 위험할 수 있씁니다. \n",
    "    \n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Classification: Prediction Bias\n",
    "- 로지스틱 회귀 예측은 편향되지 않아야 합니다. \n",
    "`예측 평균 ≈ 관찰 평군`\n",
    "\n",
    "- **예측 편향**은 두 평균이 서로 얼마나 멀리 떨어져 있는지 측정하는 수량입니다.\n",
    "예측 편향 = 예측 평균 - 이 데이터 셋의 라벨 평균\n",
    "\n",
    "- 0이 아닌 유의미한 예측 편향은 모델 어딘가에 버그가 있다는 의미입니다. \n",
    "\n",
    "- 평균적으로 전체 이메일의 1%가 스팸이라고 예를 들어 보겠습니다. 어떤 이메일에 대해 전혀 모르는 경우 메일의 1%는 스팸일 수 있다고 예측해야합니다. 마찬가지로 적절한 스팸 모델은 이메일의 1%가 스팸일 수 있다고 평귡넉으로 예측해야합니다. \n",
    "- 다시 말해서 각 이메일이 스팸으로 예측될 가능성의 평균을 내면 결과는 1%여야 합니다. 그런데 모델이 평균 20%로 예측한다면 예측 편향을 드러내는 것으로 결론을 내릴 수 있습니다.\n",
    "\n",
    "- 예측 편향이 나타날 수 있는 근본적인 원인\n",
    "    - 불완전한 특성 셋\n",
    "    - 노이즈 데이터 셋\n",
    "    - 결함이 있는 파이프라인\n",
    "    - 편향된 학습 샘플\n",
    "    - 지나치게 강한 정규화\n",
    "    \n",
    "- 예측 편향을 줄이기 위해 모델의 결과를 조정하는 **캘리브레이션 레이어**를 추가하여 학습한 모델을 사후 처리하는 방법으로 예측 편향을 수정하고자 할 수 있습니다.\n",
    "- 하지만 캘리브레이션 레이어 추가는 다음과 같은 이유로 바람직하지 않습니다.\n",
    "    - 원인이 아니라 증상만을 수정합니다.\n",
    "    - 최신의 상태로 유지하기 어려운 불안정한 시스템이 구축됩니다.\n",
    "    \n",
    "### 버케팅 및 예측 편향\n",
    "- 예측 편향을 검사할 떄 예제 하나만을 토대로 해서는 예측을 정확하게 판단할 수 없습니다. 예제의 '버킷'을 대상으로 예측 편향을 검사해야 합니다. 즉, 로지스틱 회귀의 예측 편향은 예제들을 충분히 모아서 예측된 값을 관찰된 값과 비교할 수 있는 경우에만 의미가 있습니다.\n",
    "\n",
    "- 다음 방법으로 버킷을 구성할 수 있습니다.\n",
    "    - 타겟 예측을 선형으로 분류\n",
    "    - 분위 형성\n",
    "\n",
    "- 다음과 같은 특정 모델의 캘리브레이션 플롯을 가정해보겠습니다.\n",
    "    - x축은 모델이 해당 버킷을 예측한 값의 평균을 나타냅니다.\n",
    "    - y축은 해당 버킷의 데이터 셋에 있는 값의 실제 평균을 나타냅니다.\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/BucketingBias.svg />\n",
    "<b>Figure 8. 예측 편향 곡선(대수 척도)</b>\n",
    "\n",
    "- 모델의 일부에서만 예측이 저조한 이유\n",
    "    - 학습 셋이 데이터 공간의 특정 하위 집합을 충분히 대표하지 않습니다.\n",
    "    - 데이터셋의 일부 하위 집합이 다른 하위 집합보다 노이즈가 많습니다.\n",
    "    - 모델이 지나치게 정규화되어 있습니다.(람다 값을 줄여보세요)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kyle",
   "language": "python",
   "name": "kyle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
