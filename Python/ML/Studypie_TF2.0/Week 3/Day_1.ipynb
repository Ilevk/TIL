{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3주차, 1일차 : 정규화 및 희소성 이해하기 (총 45분)\n",
    "- ### Contents \n",
    "    1. Regularization for sparsity: https://developers.google.com/machine-learning/crash-course/regularization-for-sparsity/video-lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regularization for spasity: $L_1$ 정규화 \n",
    "- 희소 벡터는 종종 많은 차원을 포함합니다. 특성 교차를 생성하면 더 많은 차원이 발생합니다. 이러한 고차원 특성 벡터가 주어지면 모델 크기가 커질 수 있으며 엄청난 양의 RAM이 필요합니다. \n",
    "- 가능하다면 고차원의 희소 벡터에서는 가중치가 정확하게 0으로 떨어지도록 유도하는 것이 좋습니다. \n",
    "- $L_2$ 정규화는 가중치를 작은 값으로 유도하지만 정확히 0으로 만들지는 못합니다.\n",
    "- 가중치가 0일 경우 모델에서 해당 특성을 삭제합니다. 특성을 없애면 RAM이 절약되고 노이즈가 줄어들 수 있습니다. \n",
    "- 적절히 선택한 정규화 항을 추가함으로써, 학습 시 수행한 최적화 문제에 이 아이디어를 적용할 수 있습니다.\n",
    "\n",
    "<br>\n",
    "\n",
    "### 1) $L_1$정규화와 $L_2$정규화 비교\n",
    "- $L_1$과 $L_2$는 서로 다른 방식으로 가중치에 페널티를 줍니다.\n",
    "    - $L_1$는 |가중치|에 페널티를 줍니다.\n",
    "    - $L_2$는 $가중치^2$에 페널티를 줍니다.\n",
    "- 결과적으로 $L_1$과 $L_2$는 서로 다르게 미분됩니다.\n",
    "    - $L_1$의 미분계수는 k(가중치와 무관한 값을 갖는 상수)입니다.\n",
    "    - $L_2$의 미분계수는 2\\*가중치 입니다.\n",
    "    \n",
    "- $L_2$의 미분계수는 매번 가중치의 x% 만큼 제거한다고 생각하면 됩니다. 이러한 성질 때문에 $L_2$는 가중치를 0으로 유도하지 않습니다. \n",
    "- $L_1$의 미분계수는 매번 가중치에서 일정 상수를 뺴는 것으로 생각하면 됩니다. 하지만 절대값으로 인해 $L_1$은 불연속성을 가지며, 이로 인해 0을 지나는 빼기 결과 값은 0이 되어 제거됩니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kyle",
   "language": "python",
   "name": "kyle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
