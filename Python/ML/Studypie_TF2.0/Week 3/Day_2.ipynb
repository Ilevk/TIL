{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3주차, 2일차 : 신경망 (총 55분)\n",
    "- ### Contents \n",
    "    1. Introduction to Neural Network: https://developers.google.com/machine-learning/crash-course/introduction-to-neural-networks/anatomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 특성 교차 단원에서 설명한 대로 이제 비선형 분류 문제를 설명하겠습니다. \n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/FeatureCrosses1.png />\n",
    "<b> Figure 1. 비선형 분류 문제 </b>\n",
    "\n",
    "'비선형'이라는 의미는\n",
    "$$b+w_1x_1+w_2x_2$$\n",
    "형태의 모델로 라벨을 정확하게 예측할 수 없다는 의미입니다. <br>\n",
    "다시 말해, '결정 표면'은 선이 아닙니다. 앞서 비선형 문제의 가능한 모델링 방식으로 특성 교차를 살펴보았습니다.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/NonLinearSpiral.png />\n",
    "<b> Figure 2. 더 복잡한 비선형 분류 문제 </b>\n",
    "\n",
    "그림 2의 데이터 셋은 선형 모델로는 해결할 수 없습니다.<br>\n",
    "신경망이 비선형 문제를 해결하는 데 어떻게 도움이 되는지 알아보기 위해 선형 모델을 그래프로 나타내 보겠습니다.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/linear_net.svg />\n",
    "<b> Figure 3. 선형 모델의 그래프</b>\n",
    "\n",
    "각 파란 원은 입력 변수를 나타냅니다. 그리고 녹색 원은 입력의 가중치 합을 표현합니다.<br>\n",
    "우리가 어떻게 해당 모델이 비선형 모델을 다루는 것을 향상 시킬 수 있을까요?\n",
    "\n",
    "### Hidden Layers\n",
    "새로 추가한 은닉층(Hidden Layer) 다음 모델에서 살펴볼 수 있습니다. 각 노란색 노드는 은닉 층의 파란 노드인 입력 노드의 가중치 합을 나타냅니다.<br>\n",
    "출력은 노란 노드들의 가중치 합이 됩니다.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/1hidden.svg />\n",
    "<b>Figure 4. 2개의 층을 가진 모델의 그래프</b>\n",
    "\n",
    "이 모델은 선형인가요?, 맞습니다. 입력의 결합으로 생성되는 출력이 여전히 선형입니다. <br>\n",
    "다음 그래프를 보겠습니다. 첫 번째 은닉층의 가중치 합으로 이루어진 두 번째 은닉층을 추가했습니다.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/2hidden.svg /> \n",
    "<b>Figure 5. 3개 층을 가진 모델의 그래프</b>\n",
    "    \n",
    "여전히 이 모델은 선형인가요?, 맞습니다. 당신이 출력을 입력의 함수로써 표현하거나 단순화할 때, 단지 또 다른 가중치 합을 얻었을 뿐입니다.<br>\n",
    "이러한 합은 비선형 문제에서 효과적이지 않습니다.\n",
    "    \n",
    "### Activation Function\n",
    "비선형 문제에 대한 모델을 만들기 위해서, 직접적으로 비선형성을 도입할 수 있습니다.<br>\n",
    "각 은닉 노드에 비선형 함수를 통과시켜 파이프를 만들 수 있습니다.<br><br>\n",
    "\n",
    "다음 그래프를 보겠습니다. 1번 은닉층의 각 노드 값들은 다음 층으로의 가중치 합을 전달하기 이전에 비선형 함수에 의해 변환됩니다.<br>\n",
    "이러한 비선형 함수를 활성화 함수라고 부릅니다.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/activation.svg />\n",
    "<b> Figure 6. 활성화 함수를 포함한 3개 층을 가진 모델의 그래프 </b>\n",
    "\n",
    "이제 활성화 함수를 포함한 추가된 계층은 더 효과적이게 되었습니다. 이러한 비선형성에 비선형성을 쌓으면 예측할 출력값과 입력 사이에 매우 복잡한 관계를 가진 모델을 만들 수 있습니다.<br>\n",
    "간단히 말하면 각 층은 효과적으로 더 복잡하게 학습합니다, 원시 입력에서 고수준의 함수로써 말이죠.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Activation Function\n",
    "시그모이드 함수는 가중치 합을 0~1 사이로 변환합니다.\n",
    "\n",
    "$$F(x)={1 \\over {1+e^{-x}}}$$\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/sigmoid.svg style='background-color:white'/>\n",
    "<b>Figure 7. 시그모이드 활성화 함수 </b>\n",
    "\n",
    "다음은 Relu(Rectified linear unit) 활성화 함수 입니다. 시그모이드 처럼 더 부드러운 형태의 함수보다 종종 더 좋은 성능을 냅니다.<br>\n",
    "그리고 계산하기 더 쉽습니다.\n",
    "\n",
    "$$F(x)=max(0,\\ x)$$\n",
    "<b>Figure 8. ReLU 활성화 함수 </b>\n",
    "\n",
    "사실 어떤 수학적인 함수던 활성화 함수로 사용할 수 있습니다. $\\sigma$가 우리의 활성화 함수라 가정해보면, 결과적으로 네트워크 내의 노드 값은 다음과 같은 수식을 따릅니다.\n",
    "\n",
    "$$\\sigma(w \\cdot x+b)$$\n",
    "\n",
    "### 정리\n",
    "방금 작성한 모델들이 주로 사람들이 '신경망' 이라고 말하는 모델의 기본적인 구성요소 입니다.\n",
    "\n",
    "- 노드, 뉴런, 층의 집합\n",
    "- 신경만 층 사이의 연결로 표현된 가중치의 집합 또는 그 아래의 층, 아래에 있는 계층은 또다른 신경망의 층일 수 있다.\n",
    "- 각 노드의 편향의 집합\n",
    "- 계층의 각 노드들의 출력을 변환하는 활성화 함수. 다른 층은 다른 활성화 함수를 가질 수도 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kyle",
   "language": "python",
   "name": "kyle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
