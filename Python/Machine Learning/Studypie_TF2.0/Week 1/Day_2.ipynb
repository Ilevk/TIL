{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1주차, 2일차 : Loss(손실)에 대해 이해하기 (총 60분)\n",
    "\n",
    "- ### Contents \n",
    "    1. Reducing Loss : https://developers.google.com/machine-learning/crash-course/reducing-loss/video-lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reducing Loss\n",
    "- 경사하강법을 사용하여 손실 함수 값을 최소화 하도록 모델을 학습한다.\n",
    "\n",
    "1. 임의의 지점에서 시작한다.\n",
    "2. 현재 위치의 경사(도함수 값)를 이용하여 경사가 줄어드는 방향으로 반복적으로 이동한다.\n",
    "3. 최적 모델을 찾는다.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/GradientDescentDiagram.svg />\n",
    "<strong>Figure 1. 반복 방식의 모델 학습</strong> \n",
    "\n",
    "- 이러한 반복 방식의 모델 학습법은 주로 대규모 데이터 셋에 적용하기 용이하여 머신러닝에서 널리 이용되고 있다.\n",
    "\n",
    "$$y'=b+w_1x_1$$\n",
    "\n",
    "- 다음과 같은 모델이 있을 때, $b$와 $w_1$의 초기 값은 어떤 값을 사용하던지 중요하지 않다.\n",
    "- 반복적으로 손실 함수를 계산하여 전체 손실이 변하지 않거나 매우 느리게 변할 때, 모델이 수렴했다고 말하며 학습을 멈춘다.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. Reducing Loss : Gradient Descent\n",
    "- 다음과 같은 손실 함수가 있다고 해보자.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/convex.svg />\n",
    "<b>Figure 2. 회귀 문제에서는 볼록 함수 모양의 손실 대 가중치 도표가 산출 됨</b>\n",
    "\n",
    "- 볼록 문제에는 기울기가 정확하게 0인 지점인 최솟값이 하나만 존재한다. 따라서 이 최솟값에서 손실 함수가 수렴하게 된다.\n",
    "- 임의의 값(시작 점)으로 $w_1$를 지정하여 시작하도록 한다.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/GradientDescentStartingPoint.svg />\n",
    "<b>Figure 3. 경사하강법의 시작점</b>\n",
    "\n",
    "- 경사하강법 알고리즘은 현재 위치에서 손실 함수의 기울기를 계산한다. 손실 함수의 편미분 벡터로 기울기가 표현된다. \n",
    "- 기울기는 벡터이므로 크기와 방향이라는 두 가지 특성을 가지고 있다.\n",
    "- 기울기는 양수일 때 손실 함수의 값이 증가하는 방향이므로 기울기의 반대 방향으로 이동하도록 한다.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/GradientDescentNegativeGradient.svg/>\n",
    "<b>Figure 4. 경사하강법은 음의 기울기를 사용한다.</b>\n",
    "\n",
    "- 현재 위치에 기울기 크기의 일부를 더하여 새로운 시작점으로 이동한다.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/GradientDescentGradientStep.svg/>\n",
    "<b>Figure 5. 기울기 보폭을 통해 손실 곡선의 다음 지점으로 이동한다.</b>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. Reducing Loss : Learning Rate\n",
    "- 기울기 벡터는 크기와 방향을 모두 갖는다. 경사하강법 알고리즘은 기울기에 학습률이라 불리는 값을 곱하여 얼마나 이동할 것인지를 결정한다.\n",
    "- 예를 들어 기울기가 2.5이고 학습률이 0.01 이라면, 경사하강법 알고리즘은 0.025 만큼 이동한다.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/LearningRateTooSmall.svg />\n",
    "<b>Figure 6. 학습률이 너무 작은 경우 </b>\n",
    "    \n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/LearningRateTooLarge.svg />\n",
    "<b>Figure 7. 학습률이 너무 큰 경우 </b>\n",
    "\n",
    "- 초모수(hyper parameter)는 프로그래머가 머신러닝 알고리즘에서 조정하는 값인데, 대부분의 머신러닝 프로그래머는 학습률을 조정하는데 상당한 시간을 소비한다.\n",
    "- 학습률이 낮은 경우 수렴하기까지 매우 오래걸리며, 학습률이 높은 경우 너무 많이 이동하여 최솟값 근처에서 진동하는 문제가 발생할 수 있다.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/LearningRateJustRight.svg />\n",
    "<b>Figure 8. 적절한 학습률</b>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3. Reducing Loss : Stochastic Gradient Descent\n",
    "- 경사하강법에서 배치(batch)는 한번 기울기를 계산하는 데 사용하는 Example의 총 개수 이다. 지금까지는 이 배치 사이즈가 전체 데이터 셋으로 가정했다.\n",
    "- 하지만 대규모의 머신러닝 프로젝트에서는 데이터 셋에 수십억 수천억 개의 데이터 샘플이 사용될 수 있으므로 배치를 줄여서 사용해야한다. \n",
    "\n",
    "\n",
    "- 오리지날 SGD는 확률적으로 선택된 1개(batch size가 1) 데이터를 가지고 반복적으로 모델을 학습하는 것, 노이즈가 매우 클 수 있다.\n",
    "- 미니배치 SGD는 우리가 일반적으로 알고 있는 batch size가 어느정도 큰 데이터를 가지고 모델을 학습하는 것, 노이즈를 줄이면서도 전체 배치보다는 더 효율적인 방법\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kyle",
   "language": "python",
   "name": "kyle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
