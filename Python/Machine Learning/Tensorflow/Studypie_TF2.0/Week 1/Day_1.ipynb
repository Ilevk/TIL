{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1주차, 1일차 : 주요 ML 용어 및 선형 회귀 이해하기 (총 38분)\n",
    "- ### Contents \n",
    "    1. Introduction to ML : https://developers.google.com/machine-learning/crash-course/ml-intro\n",
    "    2. Framing, Key ML Terminology : https://developers.google.com/machine-learning/crash-course/framing/video-lecture\n",
    "    3. Descending-into-ML : https://developers.google.com/machine-learning/crash-course/descending-into-ml/video-lecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to ML\n",
    "---\n",
    "---\n",
    "## 2. Framing : Key ML Terminology\n",
    "\n",
    "1. Labels(라벨) : 단순 선형 회귀 분석에서 `y`라고 부르는 예측할 변수를 말한다. 밀의 가격, 사진에서 뵈는 동물, 또는 오디오 클립의 의미 등이라고 이야기 함,\n",
    "\n",
    "2. Features(특성) : 단순 선형 회귀 분석에서 `x`라고 하는 입력 변수를 말한다. 간단한 머신러닝 프로젝트에서는 1개가 될 수도 있고, 복잡한 프로젝트에서는 수백만개가 될 수도 있다고 한다. 다음과 같이 표현하기도 한다.\n",
    "$$ x_1, x_2 ... x_N$$\n",
    "- 스팸 탐지 예제에서는 이메일의 단어, 보낸 사람의 주소, 메일이 보내진 시간, 특정한 문구 등이 있을 수 있다. \n",
    "\n",
    "3. Examples(예제.. 예시? 적절한 번역이 애매하다..) : 데이터의 특정한 인스턴스라고 한다. <bold>x</bold> 라고 함(bold체는 벡터를 의미한다.), 데이터 셋의 부분 집합으로 이해하는게 맞을 듯 하다.\n",
    "- Labeled Examples : 라벨링 된 Example은 모델의 학습에 사용하는 데이터이다. 스팸이다 혹은 스팸이 아니다 라고 명확하게 라벨되어 있다.\n",
    "- Unlabeled Examples : 라벨링 되지 않은 Example은 학습한 모델을 사용해 라벨을 예측하고자 하는 데이터이다. 아직 사람이 분류하지 않은 새로운 이메일을 의미한다.\n",
    "\n",
    "4. Models(모델) : Feature와 Label 사이의 관계를 모델이라고 한다. 예를 들어 스팸 탐지 모델은 Feature들을 강하게 스팸과 (might하게)연관 짓는다. \n",
    "- <strong>Training(훈련)</strong>은 모델을 생성하거나 <strong>Learning(학습)</strong>하는 것을 의미한다. 모델에게 Labeled된 Example들을 보여주면서 점진적으로 Feature와 Label 의 관계를 학습할 수 있도록 한다.\n",
    "- <strong>Inference(추론)</strong>은 훈련된 모델을 Unlabeld된 Example에 적용하는 것을 의미한다. 훈련된 모델을 사용하여 `y'`를 만들어 낸다. \n",
    "\n",
    "5. Regression vs Classification\n",
    "- 회귀 모델은 연속적인 변수를 예측한다. 예를 들어 캘리포니아의 집값, 유저들이 해당 광고를 클릭할 확률 등이 있다.\n",
    "- 분류 모델은 이산적인 변수를 예측한다. 예를 들어 주어진 이메일이 스팸인지 혹은 스팸이 아닌지, 해당 이미지가 강아지인지 고양이인지 햄스터인지 등.\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Descending into ML\n",
    "1. Linear Regression(선형회귀) : 귀뚜라미 울음소리와 기온의 관계\n",
    "- 온도가 높을수록 귀뚜라미가 자주 운다고 한다. 데이터를 통해 알아보자.(안타깝게 데이터를 주진 않는다.. ) \n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/CricketPoints.svg/>\n",
    "<strong>Figure 1. 분당 울음 횟수 vs. 섭씨 온도</strong> \n",
    "\n",
    "- 해당 이미지를 보면, 온도가 오름에 따라 울음 횟수가 늘어난다는걸 확인할 수 있다. 그렇다면 이 관계는 선형이라고 할 수 있다. 직선 하나를 그려보면 대략적인 관계를 나타낼 수 있다.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/CricketLine.svg/>\n",
    "<strong>Figure 2. 선형 관계</strong> \n",
    "\n",
    "- 직선이 모든 점을 지나가지는 않는다. 하지만, 해당 직선은 울음 횟수와 기온의 관계를 명확하게 보여준다. 다음과 같은 식으로 직선을 나타낼 수 있다.\n",
    "\n",
    "$$ y=mx+b $$\n",
    "\n",
    "- $y$ : 섭씨 온도를 나타낸다. -> 우리가 예측할 값이 된다.\n",
    "- $m$ : 직선의 기울기를 나타낸다.\n",
    "- $x$ : 분당 울음 횟수를 나타낸다. -> 우리가 입력으로 사용할 feature(특성)이 된다.\n",
    "- $b$ : y-절편을 나타낸다.\n",
    "\n",
    "\n",
    "- 머신러닝의 Convention으로 표현하면, 조금 다르게 표현된다. \n",
    "$$ y'=b+w_1x_1$$ \n",
    "- $y`$ : 예측된 라벨\n",
    "- $b$ : 편향(bias)을 나타낸다(y-절편). (가끔 w0로 표현하기도 한다.)\n",
    "- $w_1$ : feature 1 의 가중치가 된다. 가중치는 전통적인 직선의 기울기인 $m$과 같다.\n",
    "- $x_1$ : 입력이라고 알려진 feature를 나타낸다.\n",
    "\n",
    "\n",
    "- 변수를 여러개 사용하면 다음과 같이 나타내어진다.\n",
    "$$y'=b+w_1x_1+w_2b_2+w_3x_3 $$\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Training and Loss(학습과 손실)\n",
    "- 모델을 학습하는건 단순하게 Labeled example로부터 좋은 가중치와 편향의 값을 배우는 것을 의미한다. 지도 학습에서 머신러닝 알고리즘은 손실을 최소화하는 모델을 찾도록 시도하거나 실험하여 모델을 만든다. 이러한 것을 ERM(Empirical Risk Minimization) 경험적 위험 최소화 라고 부른다.\n",
    "- 손실은 잘못된 예측의 패널티이며, 하나의 Example에서 모델이 얼마나 나쁘게 예측했는지를 나타내는 수치이다.\n",
    "- 모델이 완벽하다면 손실은 0이며 손실이 크다면 모델이 완벽하지 않다는 것을 의미한다. \n",
    "- 모델 학습은 모든 Example 사이에서 평균적으로 낮은 손실을 갖는 가중치와 편향의 집합을 찾는 것을 목표로 한다.\n",
    "\n",
    "\n",
    "\n",
    "- 화살표는 손실을 나타내며, 파랑색 선은 예측을 나타낸다.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/LossSideBySide.png/>\n",
    "\n",
    "<strong>Figure 3. 왼쪽은 높은 손실을 갖는 모델, 오른쪽은 낮은 손실을 갖는 모델</strong>\n",
    "\n",
    "- 왼쪽의 Plot은 오른쪽의 Plot에 비해 더 긴 화살표를 가지고 있다. 명확하게 오른쪽 Plot 더 좋은 예측 모델이라고 할 수 있다.\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sqaured Loss(제곱 손실) : a popular loss function(가장 인기 있는 함수) \n",
    "- 선형 회귀 모델에서 Sqaured Loss라는 손실 함수를 살펴볼 예정이다. ($L_2\\ Loss$라고도 알려져 있다.) 제곱 손실 함수는 다음과 같이 표현할 수 있다.\n",
    "- `참 값과 예측 값 사이의 오차에 대한 제곱`\n",
    "- (observation - predictions(x))$^2$\n",
    "- (y - y')$^2$\n",
    "\n",
    "\n",
    "#### Mean square error(MSE) 는 제곱 손실 함수의 평균 값을 나타낸다. MSE를 계산하려면 모든 Example의 제곱 손실의 합을 Example의 개수로 나누어주면 된다.\n",
    "$$ MSE={1 \\over {N}} \\sum_{(x,y)\\in D}{(y-prediction(x))^2} $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kyle",
   "language": "python",
   "name": "kyle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
