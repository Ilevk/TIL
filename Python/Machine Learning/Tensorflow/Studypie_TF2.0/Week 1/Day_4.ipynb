{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1주차, 4일차 : 일반화 이해하기, 학습 / 테스트 셋 이해하기, 검증 셋 이해하기 (총 1시간 20분)\n",
    "\n",
    "- ### Contents \n",
    "    1. Generalization : https://developers.google.com/machine-learning/crash-course/generalization/video-lecture\n",
    "    2. Training and Test Sets : https://developers.google.com/machine-learning/crash-course/training-and-test-sets/video-lecture\n",
    "    3. Validation Set : https://developers.google.com/machine-learning/crash-course/validation/check-your-intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generalization : Peril of Overfitting\n",
    "- 이번에는 일반화에 초점을 맞추고 일반화의 개념에 대해 알아본다. \n",
    "- 그림의 각 점은 숲에서 나무의 위치를 나타낸다고 가정한다.\n",
    "- 파랑색 점은 병든 나무, 주황색 점은 건강한 나무를 나타낸다. \n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/GeneralizationA.png />\n",
    "<b>Figure 1. 병든(파란색) 나무와 건강한(주황색) 나무 </b>\n",
    "\n",
    "- 병든 나무와 건강한 나무를 예측하는 데 적합한 모델은 무엇일까? 다음과 같은 모델은 주어진 데이터를 잘 구분한다.\n",
    "- 손실 함수의 값이 적게 발생하는 이 모델은 좋은 모델일까?\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/GeneralizationB.png />\n",
    "<b>Figure 2. 병든 나무와 건강한 나무를 구분하기 위한 복잡한 모델</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그림 3은 모델에 새로운 데이터가 추가되었을 때 발생하는 문제점을 보여준다. \n",
    "- 해당 모델은 새로운 데이터에 대해 적합하지 않아보인다.\n",
    "\n",
    "<img src = https://developers.google.com/machine-learning/crash-course/images/GeneralizationC.png />\n",
    "<b>Figure 3. 새 데이터를 잘못 예측한 모델 </b>\n",
    "\n",
    "- 이러한 결과를 학습 데이터에 모델이 과적합(Overfitting) 되었다고 표현한다. \n",
    "- 머신러닝의 목표는 숨겨진 실제 확률 분포에서 추출되는 새로운 데이터를 잘 예측하는 것이다. 하지만 모든 데이터를 볼 수 없으며 학습 데이터 셋에서만 샘플을 확인할 수 있다.\n",
    "\n",
    "`ML 모델이 덜 복잡할수록 샘플의 특성 때문이 아니어도 좋은 경험적 결과를 얻을 가능성이 높습니다. - Occam's razor`\n",
    "\n",
    "- 오캄의 면도날 법칙은 통계적 학습 이론 및 컴퓨터 학습 이론 분야에서 공식화 되었고, 다음과 같은 요인을 기반으로 모델이 일반화 되는 정도를 설명하는 일반화 한계를 개발하였다. \n",
    "    - 모델의 복잡성\n",
    "    - 학습 데이터에 대한 모델의 성능\n",
    "    \n",
    "    \n",
    "- 이전의 보지 못한 데이터를 잘 예측하도록 하기 위해서는 주어진 데이터를 두 하위 데이터 셋으로 나누어 모델을 학습하고 평가할 수 있다.\n",
    "    - 학습 셋 : 모델을 학습시키기 위한 하위 셋\n",
    "    - 테스트 셋 : 모델을 테스트하기 위한 하위 셋\n",
    "- 테스트 셋에서 성능이 좋으면 일반적으로 다음과 같은 경우 새 데이터에서도 성능이 좋다\n",
    "    - 테스트 셋이 충분히 크다.\n",
    "    - 같은 테스트 셋을 반복적으로 사용하지 않았다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML 세부사항\n",
    "- 일반화에서는 기본적으로 다음 세 가지 사항을 가정한다.\n",
    "    - 분포에서 독립적이고 동일하게(i.i.d. , Independent and identically distributed random variables) 임의로 데이터를 추출한다. \n",
    "    - 분포가 정상성(stationary)을 보인다. 데이터 셋 내에서 분포가 변하지 않는다.\n",
    "    - 같은 분포에서 추출된 데이터이다.\n",
    "    \n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training and Test Sets : Splitting Data\n",
    "- 학습 셋 : 모델을 학습시키기 위한 데이터 셋의 일부분\n",
    "- 테스트 셋 : 모델을 테스트하기 위한 데이터 셋의 일부분\n",
    "- 데이터 셋 하나를 다음과 같이 분할해 볼 수 있습니다.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/PartitionTwoSets.svg />\n",
    "<b>Figure 1. 데이터 셋 하나를 학습 셋과 테스트 셋으로 분할</b>\n",
    "\n",
    "- 테스트 셋은 통계적으로 유의미한 결과를 도출할 만큼 커야하고, 데이터 셋을 대표할 수 있어야한다.\n",
    "- 상기 두 가지 조건을 만족한다면 이제 새로운 데이터에 대해서 일반화 될 수 있는 모델을 만들어야한다. \n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/TrainingDataVsTestData.svg />\n",
    "<b>Figure 2. 학습된 모델을 테스트 데이터로 검증 </b>\n",
    "\n",
    "- 테스트 데이터로 모델을 학습 하지 않도록 주의\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Validation Set : Another Partition\n",
    "- 테스트 셋을 기준으로 파라미터 튜닝을 하다보면 테스트 셋 자체에도 과적합 되는 문제가 발생할 수 있다. \n",
    "- 검증 셋을 추가해보자.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/WorkflowWithTestSet.svg />\n",
    "<b>Figure 1. 가능한 워크플로우 </b>\n",
    "\n",
    "- 이 그림에서 모델 조정이란, 학습률 변경, 특성 추가 또는 삭제, 완전히 새로운 모델 설계와 같이 모델에서 가능한 모든 요소를 조정함을 의미한다.\n",
    "- 데이터 셋을 검증 셋까지 셋으로 나누면 과적합 가능성을 크게 낮출 수 있다.\n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/PartitionThreeSets.svg />\n",
    "<b>Figure 2. 데이터 셋 하나를 세개로 분할</b>\n",
    "\n",
    "- 검증 셋을 사용하여 학습 셋의 결과를 평가한다. 검증 셋의 결과가 좋았을 때 테스트 셋으로 다시 한번 평가해본다. \n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/WorkflowWithValidationSet.svg />\n",
    "<b>Figure 3. 워크플로우 개선</b>\n",
    "\n",
    "1. 검증 셋에서 가장 우수한 결과를 보이는 모델을 선택한다.\n",
    "2. 테스트 셋을 기준으로 해당 모델을 재차 확인한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kyle",
   "language": "python",
   "name": "kyle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
