{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4주차, 4일차 : 공정성 이해하기 (총 70분)\n",
    "- ### Contents \n",
    "    1. Fairness: https://developers.google.com/machine-learning/crash-course/fairness/video-lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Firness: Type of Bias\n",
    "머신러닝 모델이라고 해서 본질적으로 객관적인 것은 아닙니다. 엔지니어는 학습 사례로 이루어진 데이터셋을 입력하여 모델을 학습시키며 데이터의 사전준비과 선정에 사람이 관여하기 때문에 모델의 예측이 편향되기 쉽습니다. \n",
    "\n",
    "### 보고 편형\n",
    "- 데이터 셋에 수집된 이벤트, 속성 및 결과의 빈도가 실제 빈도를 정확하게 반영하지 않을 때 나타납니다. \n",
    "- 이는 사람들이 '말할 필요도 없다고 느끼는' 일반적인 상황은 언급하지 않고 특별히 기억할 만하거나 특이한 상황만을 기록하려는 경향이 있기 때문에 발생합니다.\n",
    "\n",
    "### 자동화 편향\n",
    "- 두 시스템의 오류율과 관계없이 자동화 시스템이 생성한 결과를 비자동화 시스템이 생성한 결과보다 선호하는 경향을 말합니다.\n",
    "\n",
    "### 표본 선택 편향\n",
    "- 데이터 셋의 사례가 실제 분포를 반영하지 않는 방식으로 선정된 경우 발생합니다. \n",
    "    - 포함 편향: 선택된 데이터가 대표성을 갖지 않습니다.\n",
    "    - 무응답 편향(또는 응답 참여 편향): 데이터 수집 시 참여도의 격차로 인해 데이터가 대표성을 갖지 못합니다.\n",
    "    - 표본 추출 편향: 데이터 수집 과정에서 적절한 무작위 선택이 적용되지 않았습니다.\n",
    "    \n",
    "### 그룹 귀인 편향\n",
    "- 개인의 특성을 개인이 속한 그룹 전체의 특성으로 일반화하려는 경향을 말합니다. \n",
    "    - 내집단 편향: 자신이 소속된 그룹 또는 본인도 공유하는 특성을 가진 그룹의 구성원을 선호하는 경향\n",
    "    - 외부 집단 동질화 편향: 자신이 속하지 않은 그룹의 개별 구성원에 관해 고정 관념을 갖거나 그들이 모두 동일한 특징을 가진다고 판단하는 경향입니다.\n",
    "    \n",
    "### 내재적 편향\n",
    "- 일반적으로 적용할 필요가 없는 자신의 정신적 모델과 개인적 경험을 바탕으로 가정할 때 발생합니다.\n",
    "    - 확증 편향: 모델을 만드는 사람이 자기도 모르게 이미 가지고 있는 믿음이나 가설을 긍정하는 방향으로 데이터를 처리\n",
    "    - 실험자 편향: 모델을 만드는 사람이 자신의 원래 가설과 일치할 때까지 반복해서 모델을 학습시키는 것\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Firness: Identifying Bias\n",
    "모델에서 데이터를 가장 잘 표현할 방법을 찾기 위해 데이터를 살펴볼 때 공정성 문제를 염두에 두고 편향의 원인이 될 수 있는 요소를 사전에 점검하는 것이 중요합니다.\n",
    "<br><br>\n",
    "\n",
    "### 특성 값 누락\n",
    "데이터 셋의 다수 예에서 값이 누락된 특성이 하나 이상 있는 경우 데이터 셋의 주요 특성 중 일부가 제대로 표현되지 않았음을 나타내는 지표일 수 있습니다.<br>\n",
    "\n",
    "아래의 표는 pandas `DataFrame`에 보관되어 있고 `DataFrame.describe`를 통해 생성된 캘리포니아 주택 데이터셋에 있는 특성의 하위 집합에 관한 주요 통계 요약을 보여줍니다. 모든 특성의 `count`가 17000이라는 것은 누락된 값이 없음을 나타냅니다.\n",
    "\n",
    "<img src=./imgs/Day_4_Figure_1.png />\n",
    "<br>\n",
    "\n",
    "3가지 특성(`population`, `households`, `median_income`)의 count가 `3000`이라고 가정해 보겠습니다.<br>\n",
    "다시 말하면 각 특성에 14,000개의 누락된 값이 있는 것입니다.\n",
    "\n",
    "<img src=./imgs/Day_4_Figure_2.png />\n",
    "\n",
    "14,000개의 값이 누락되어 가구의 평균 소득과 주택 가격의 중앙값을 정확히 연관시키기 훨씬 어려워졌습니다. 이 데이터의 모델을 학습하기 전에 누락된 값의 원인을 신중하게 조사하여 소득 및 인구 데이터 누락의 원인이 될 수 있는 잠재적인 편향이 없는지 확인하는 것이 좋습니다.\n",
    "\n",
    "\n",
    "### 예기치 않은 특성 값\n",
    "또한 데이터를 살펴볼 때 특이하거나 비정상적인 특성 값을 포함하는 예가 있는지 확인해 보아야 합니다. 이와 같이 예기치 않은 특성 값이 있다는 것은 데이터 수집 중에 문제가 발생했거나 편향을 일으킬 수 있는 기타 부정확성이 있음을 나타낼 수 있습니다.\n",
    "\n",
    "### 데이터 격차\n",
    "특정 그룹이나 특성이 실제보다 과소 또는 과대 표현되는 모든 종류의 데이터 격차로 인해 모델에 편향이 생길 수 있습니다.<br><br>\n",
    "학습 셋과 검증 셋으로 나누기 전에 데이터 셋을 무작위로 섞지 않아서 확연한 데이터 격차가 생길 수 있습니다. \n",
    "\n",
    "<img src=https://developers.google.com/machine-learning/crash-course/images/california_housing_state_map.svg style='background-color:white' />\n",
    "<b>Figure 1. 캘리포니아 주 지도 위에 캘리포니아 주택 데이터 셋의 데이터를 오버레이한 그림</b>\n",
    "\n",
    "- 각각의 점은 주택 단지를 나타내며, 파란색은 주택 가격 중앙값이 낮은 곳, 빨간색은 높은 곳을 나타냅니다.\n",
    "\n",
    "이와 같이 전체를 잘 대표하지 못하는 샘플을 캘리포니아 주 전체의 주택 가격 예측을 위한 모델을 학습하는 데 사용했다면, 캘리포니아 주 남부 주택 데이터가 없는 것이 문제가 될 수 있습니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fairness: Evaluating for Bias\n",
    "모델을 평가할 때 전체 테스트 또는 검증 셋을 기준으로 계산된 지표가 모델의 공정성에 관해 항상 정확한 모습을 보여주는 것은 아닙니다.\n",
    "<br><br>\n",
    "환자의 의료 기록 1,000개로 구성된 검증셋이 있다고 가정하고, 그를 바탕으로 종양의 유무를 예측하는 새로운 모델을 만들었다고 합시다. 500개 기록은 여성 환자의 기록이고 나머지 500개는 남성 환자의 기록입니다. 다음 Confusion Matrix는 전체 1,000개 사례의 결과를 요악한 것입니다.\n",
    "\n",
    "참양성(TP):16 | 거짓양성(FP): 4\n",
    ":---:|:---:\n",
    "거짓음성(FN):6 | 참음성(TN): 974\n",
    "\n",
    "$$ 정밀도={{TP}\\over{TP+FP}}={{16}\\over{16+4}}=0.800$$\n",
    "$$ 재현율={{TP}\\over{TP+FN}}={{16}\\over{16+6}}=0.727$$\n",
    "\n",
    "정밀도가 80%이고 재현율이 72.7% 이므로 유망한 결과로 보입니다. 하지만 각 환자 셋에 관한 결과를 따로 계산하면 어떻게 될까요? 결과를 두 개(여성 환자와 남성 환자)의 개별 Confution Matrix로 나누어 봅시다.\n",
    "\n",
    "#### 여성 환자 결과\n",
    "\n",
    "참양성(TP):10 | 거짓양성(FP): 1\n",
    ":---:|:---:\n",
    "거짓음성(FN):1 | 참음성(TN): 488\n",
    "\n",
    "\n",
    "$$ 정밀도={{TP}\\over{TP+FP}}={{10}\\over{10+4}}=0.909$$\n",
    "$$ 재현율={{TP}\\over{TP+FN}}={{10}\\over{10+6}}=0.909$$\n",
    "\n",
    "- 여성 환자\n",
    "    - 실제로 종양이 있었던 여성 환자 11명에 관해 모델은 10명의 환자를 양성으로 정확하게 예측하여 90.9%의 재현율을 보였습니다. 다시 말해 <b>이 모델은 여성 환자 사례의 9.1%에 관해서는 종양 진단을 놓친 것입니다.</b>\n",
    "    - 마찬가지로 모델이 여성 환자 종양에 양성을 반환할 때 11개 중 10개 사례에서 정확했습니다. 정밀도 90.9% 다시 말해 <b>이 모델은 여성 환자 사례의 9.1%에 관해서는 종양을 잘못 예측한 것입니다.</b>\n",
    "\n",
    "#### 남성 환자 결과\n",
    "\n",
    "참양성(TP):6 | 거짓양성(FP): 3\n",
    ":---:|:---:\n",
    "거짓음성(FN):5 | 참음성(TN): 486\n",
    "\n",
    "\n",
    "$$ 정밀도={{TP}\\over{TP+FP}}={{6}\\over{1+3}}=0.909$$\n",
    "$$ 재현율={{TP}\\over{TP+FN}}={{6}\\over{6+5}}=0.909$$\n",
    "\n",
    "- 남성 환자\n",
    "    - 하지만 실제로 종양이 있었던 남성 환자 11명에 관해 모델은 6명의 환자를 양성으로 정확하게 예측하여 54.5%의 재현율을 보였습니다. 다시 말해 <b>이 모델은 남성 환자 사례의 45,5%에 관해서는 종양 진단을 놓친 것입니다.</b>\n",
    "    - 모델이 남성 환자의 종양에 양성을 반환할 때 9개 중 6개 사례에서만 정확했습니다. 정밀도 66.7% 다시 말해 <b>이 모델은 남성 환자 사례의 33.3%에 관해서는 종양을 잘못 예측한 것입니다.</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kyle",
   "language": "python",
   "name": "kyle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
