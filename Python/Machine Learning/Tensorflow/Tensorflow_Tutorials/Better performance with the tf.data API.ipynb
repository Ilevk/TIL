{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.data API를 사용한 더 나은 성능\n",
    "##### url: https://www.tensorflow.org/guide/data_performance?hl=en#overview\n",
    "\n",
    "- 목차\n",
    "    - 개요\n",
    "    - 자원\n",
    "    - 설정\n",
    "        - 데이터셋\n",
    "        - 학습 루프\n",
    "    - 성능 최적화\n",
    "        - 간단한 접근법\n",
    "        - 프리페칭\n",
    "        - 데이터 추출 병렬화\n",
    "        - 데이터 변환 병렬화\n",
    "        - 캐싱\n",
    "        - 매핑 함수 벡터화하기\n",
    "        - 메모리 사용 흔적 줄이기\n",
    "    - 모범 사례 요약\n",
    "## 개요\n",
    "GPU들과 TPU들은 단일 훈련 스탭을 수행하기 위한 소요 시간을 급격히 줄일 수 있습니다. <br>\n",
    "최고 성능을 달성하는 것은 현재 스텝이 끝나기 전에 다음 스텝의 데이터를 운반하는 효율적인 입력 파이프라인이 요구됩니다.<br>\n",
    "`tf.data` API는 유연하고, 효율적인 입력 파이프라인을 생성하는 것을 도와줍니다.<br>\n",
    "해당 문서는 매우 성능이 좋은 텐서플로우 입력 파이프라인을 생성하기 위해 `tf.data` API를 어떻게 사용하는지 보여줍니다.<br><br>다음으로 넘어가기 전에 `tf.data` API를 어떻게 사용하는지 배울 수 있는 \"[Build TensorFlot input pipelines](https://www.tensorflow.org/guide/data)\" 가이드를 읽어보세요.\n",
    "\n",
    "## 자원\n",
    "- [Build TensorFlot input pipelines](https://www.tensorflow.org/guide/data)\n",
    "- [`tf.data.Dataset'](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 가이드 전반에서, 반복적으로 데이터셋과 성능 측정을 할 예정입니다.<br>\n",
    "다른 인자에 의해, 동일한 성능의 벤치마크를 만드는 것은 어려울 수 있습니다.\n",
    "\n",
    "- 현재 CPU 로드율\n",
    "- 네트워크 트래픽\n",
    "- 캐시 같은 복잡한 매카니즘 등\n",
    "\n",
    "동일한 성능의 벤치마크를 제공하기 위해 인공적으로 예제를 만들겠습니다.\n",
    "\n",
    "### 데이터 셋\n",
    "`tf.data.Dataset`를 상속 받은 `ArtificialDataset` 클래스를 정의합니다.<br>\n",
    "해당 데이터셋은 다음과 같은 특징을 갖습니다.\n",
    "\n",
    "- `num_samples` 만큼의 샘플을 생성합니다. (기본값 3)\n",
    "- 파일을 열고 첫 번째 항목을 읽기 전에 잠시 대기합니다.\n",
    "- 파일에서 데이터를 읽어와 각 아이템을 반환할 때마다 잠시 대기합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtificialDataset(tf.data.Dataset):\n",
    "    def _generator(num_samples):\n",
    "        # 파일 열기\n",
    "        time.sleep(0.03)\n",
    "        \n",
    "        for sample_idx in range(num_samples):\n",
    "            # 파일로부터 (line, record)로 이루어진 데이터를 읽습니다.\n",
    "            time.sleep(0.015)\n",
    "            \n",
    "            yield (sample_idx,)\n",
    "    \n",
    "    def __new__(cls, num_samples=3):\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            cls._generator,\n",
    "            output_types=tf.dtypes.int64,\n",
    "            output_shapes=(1,),\n",
    "            args=(num_samples,)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 데이터셋은 `tf.data.Datast.range`와 비슷하지만, 각 샘플의 시작과 사이에 고정된 딜레이가 추가되었습니다.\n",
    "\n",
    "### 학습 루프\n",
    "전반에 걸쳐 데이터셋을 반복하는 것이 얼마나 오래걸리는지 측정하기 위해 더미 학습 루프를 작성해야합니다.<br>\n",
    "학습 시간을 시뮬레이팅 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(dataset, num_epochs=2):\n",
    "    start_time = time.perf_counter()\n",
    "    for epoch_num in range(num_epochs):\n",
    "        for sample in dataset:\n",
    "            # 학습을 수행 하는 단계\n",
    "            time.sleep(0.01)\n",
    "    tf.print('수행 시간: ', time.perf_counter() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능 최적화하기\n",
    "어떻게 성능이 최적화될 수 있는지 보여주기 위해서, `ArtificialDataset`의 성능을 개선해야 합니다.\n",
    "\n",
    "### 간단한 접근 방법\n",
    "트릭을 사용하지 않고 간단한 파이프라인으로 시작해봅시다. 현재 데이터셋은 다음과 같이 반복됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수행 시간:  0.26520297399838455\n"
     ]
    }
   ],
   "source": [
    "benchmark(ArtificialDataset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같이, 수행 시간이 어떻게 소비되었는지 볼 수 있습니다.\n",
    "\n",
    "<img src=https://www.tensorflow.org/guide/images/data_performance/naive.svg />\n",
    "\n",
    "학습 단계를 수행하는 것은 다음을 포함합니다. \n",
    "- 파일이 열리지 않았다면, 파일을 연다.\"\n",
    "- 데이터 엔트리를 파일로부터 불러온다.\n",
    "- 학습을 위해 데이터를 사용한다.\n",
    "\n",
    "이와 같이 간단하게 동기화된 구현에서 모델은 파이프라인이 데이터를 파일로부터 불러오는 동안 유휴(idle) 상태에 있게 됩니다.<br>\n",
    "반대로 모델이 학습하는 동안 입력 파이프라인은 유휴 상태에 있게 됩니다.<br>\n",
    "이와 같이 학습 단계의 소요 시간은 파일 열기, 데이터 불러오기, 학습 시간의 합으로 이루어집니다.<br><br>\n",
    "다음 섹션에서는 입력 파이프라인을 구축하고, 성능이 뛰어난 텐서플로우 입력 파이프라인 설계의 모범 사례를 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프리페치(Prefetching)\n",
    "프리페치는 학습 단계에서 모델 수행 및 전처리와 동시에 수앻됩니다. `s`번째 학습 단계에서 모델이 수행되는 동안, 입력 파이프라인은 `s+1`번째 데이터를 미리 읽습니다. <br>\n",
    "이러한 방법으로 학습에 소요되는 시간과 데이터를 추출하기 위해 소요되는 시간을 최대한 줄일 수 있습니다.<br><br>\n",
    "`tf.data` API는 `tf.data.Dataset.prefetch` 변환을 제공합니다. 해당 함수는 데이터를 소비하는 시간과 데이터를 생성하는 시간을 분리하는 작업에 사용될 수 있습니다.<br>\n",
    "특히, 해당 함수는 백그라운드 스레드와 데이터가 요청되기 이전에 입력 데이터셋으로부터 원소를 프리페치하기 위한 내부 버퍼를 사용합니다.<br>\n",
    "프리페치 될 원소의 수는 한번의 학습 단계에서 사용될 배치의 크기만큼이(또는 가능한 더 크게) 되어야 합니다.<br>\n",
    "이러한 값을 수동으로 지정할 수 있거나 수행 중 동적으로 값을 튜닝하는 `tf.data` 런타임을 수행할 `tf.data.experimental.AUTOTUNE`으로 설정할 수 있습니다.<br><br>\n",
    "프리페치 변환은 'Producer' 작업과 'Consumer' 작업이 겹칠 때마다 시간적 이익을 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수행 시간:  0.21593949702219106\n"
     ]
    }
   ],
   "source": [
    "benchmark(\n",
    "    ArtificialDataset()\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://www.tensorflow.org/guide/images/data_performance/prefetched.svg />\n",
    "\n",
    "샘플 0에 대한 학습이 수행되는 동안에 입력 파이프라인이 샘플 1의 데이터를 읽고 있는 것을 확인할 수 있습니다. 당연히 그 다음도 동일하게 이어집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 추출 병렬화\n",
    "실제 현업에서는, 입력 데이터는 원격 저장소에 있을 확률이 높습니다.(ex, Google Cloud Storage 또는 HDFS 등)<br>\n",
    "로컬 저장소에서 잘 작동하던 데이터 파이프라인일지라도 원격으로 데이터를 읽게되면 병목 현상이 발생할 수 있습니다. 이는 로컬 저장소와 원격 저장소의 차이 때문에 발생합니다.\n",
    "\n",
    "- **Time-to-first-byte:** 원격 저장소에 저장된 파일의 첫 번째 바이트를 읽는 작업이 로컬 저장소보다 오래걸릴 수 있습니다.\n",
    "- **Read throughput:** 원격 저장소는 일반적으로 넓은 대역폭을 제공합니다. 하지만, 파일 하나를 읽는 것은 그 대역폭의 작은 부분만 활용하게 됩니다.\n",
    "\n",
    "추가적으로 원본 바이트를 메모리에 적재하게 되면, 추가적인 컴퓨팅 자원이 요구되는 데이터 해독 및 역 직렬화가 필요할 수 있습니다. (ex, protobuf) <br>\n",
    "이러한 오버헤드는 데이터가 로컬 또는 원격에 저장되었는지 유무에 관계 없이 발생합니다. 하지만, 원격 저장소의 경우 프리페치가 효과적으로 이루어지지 않으면 더 나쁜 경우가 발생합니다.<br><br>\n",
    "다양한 데이터 추출의 오버헤드를 완화하기 위해, `tf.data.Dataset.interleave` 변환은 데이터 로드 단계에서 다른 데이터셋의 내용을 인터리빙하는 병렬화로써 사용될 수 있습니다. <br>\n",
    "겹쳐지는 데이터 셋의 수는 `cycle_length` 인자에 의해 명확히 정해질 수 있습니다. 또한, 병렬화 수준(level)은 `num_parallel_calls` 인자에 의해 정해질 수 있습니다. <br>\n",
    "`prefetch` 변환과 비슷하게, `interleave` 변환은 `tf.data` 런타임에서 병렬화 수준 결정을 위임하는 `tf.data.experimental.AUTOTUNE`를 지원합니다.<br><br>\n",
    "#### 순차적 인터리브\n",
    "`tf.data.Dataset.interleave` 변환의 기본 인자는 두개의 데이터셋으로 부터 순차적으로 단일 인터리브 샘플을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수행 시간:  0.22327319398755208\n"
     ]
    }
   ],
   "source": [
    "benchmark(\n",
    "    tf.data.Dataset.range(2)\n",
    "    .interleave(ArtificialDataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://www.tensorflow.org/guide/images/data_performance/sequential_interleave.svg />\n",
    "\n",
    "해당 플랏은 `interleave` 변환이 작동 방식을 보여줍니다. 2개의 사용 가능한 데이터셋으로부터 번갈아가며 샘플을 불러옵니다.<br>\n",
    "하지만, 성능 향상이 일어나지는 않았습니다.<br><br>\n",
    "\n",
    "#### 인터리브 병렬화\n",
    "\n",
    "`interleave` 변환의 `num_parallel_calls` 인자를 사용해 보겠습니다. <br>\n",
    "다수의 데이터셋을 병렬적으로 불러오며, 파일을 여는 것에 대한 대기 시간을 줄여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수행 시간:  0.15036666701780632\n"
     ]
    }
   ],
   "source": [
    "benchmark(\n",
    "    tf.data.Dataset.range(2)\n",
    "    .interleave(\n",
    "        ArtificialDataset,\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://www.tensorflow.org/guide/images/data_performance/parallel_interleave.svg />\n",
    "2개의 데이터셋이 병렬화 되어 읽어지고 있으며, 전역 데이터처리 시간이 감소되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 변환 병렬화\n",
    "데이터를 준비할 때, 입력 원소들은 전처리를 필요로 할 수 있습니다. 이를 위해 `tf.data` API는 입력 데이터셋의 각 원소에 대해 사용자 정의 함수를 적용하는 `tf.data.Dataset.map` 변환을 제공합니다.<br>\n",
    "입력 원소는 서로 독립적이기 때문에 전처리 연산은 다중 CPU 코어에 의해 병렬화 될 수 있습니다.<br>\n",
    "이는 `prefetch` 및 `interleave`와 비슷하게 `map` 변환에서 제공하는 `num_parallel_calls` 인자를 통해 병렬화 수준을 지정할 수 있습니다.<br><br>\n",
    "최적의 `num_parallel_calls` 인자의 값을 선택하는 것은, 사용자의 하드웨어와 학습 데이터의 특성 및 map 함수의 비용 그리고 같은 시간에 CPU에서 일어나는 연산들에 달려있습니다. <br>\n",
    "간단하면서 자주 사용되는 값은 사용가능한 CPU 코어의 수로 지정됩니다.`prefetch`와 `interleave` 변환에서 그랬듯이 `map` 변환은 `tf.data` 런타임에서 병렬화 수준 결정을 위임하는 `tf.data.experimental.AUTOTUNE`를 지원합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapped_function(s):\n",
    "    tf.py_function(lambda: time.sleep(0.03), [], ())\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순차적 매핑\n",
    "베이스라인 예제처럼 병렬화 없이 `map` 변환을 사용하여 시작해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수행 시간:  0.466817053995328\n"
     ]
    }
   ],
   "source": [
    "benchmark(\n",
    "    ArtificialDataset()\n",
    "    .map(mapped_function)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://www.tensorflow.org/guide/images/data_performance/sequential_map.svg />\n",
    "\n",
    "간단하게 한번의 반복에 대해 파일 열기, 읽기, 전처리(매핑) 그리고 학습에 소요된 전체 시간을 보여줍니다.<br><br>\n",
    "\n",
    "### 병렬적 매핑\n",
    "이제, 다중 샘플에 대해 병렬적으로 같은 전처리 함수를 사용해 적용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수행 시간:  0.29163806699216366\n"
     ]
    }
   ],
   "source": [
    "benchmark(\n",
    "    ArtificialDataset()\n",
    "    .map(\n",
    "        mapped_function,\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 전처리 단계가 겹쳐진 것을 확인할 수 있습니다. 한번의 반복에 대해 전체 소요 시간이 줄어들었습니다.<br><br>\n",
    "\n",
    "### 캐싱\n",
    "`tf.data.Dataset.cache` 변환은 데이터셋을 메모리 또는 로컬 저장소에 캐싱할 수 있습니다.<br>\n",
    "캐싱은 파일을 열거나 데이터를 읽는 등 매 에폭에서 수행되던 연산을 줄일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수행 시간:  0.432162375014741\n"
     ]
    }
   ],
   "source": [
    "benchmark(\n",
    "    ArtificialDataset()\n",
    "    .map( # 캐시 하기전에 시간이 소요되는 연산 적용\n",
    "        mapped_function\n",
    "    ).cache(\n",
    "    ),\n",
    "    5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://www.tensorflow.org/guide/images/data_performance/cached_dataset.svg />\n",
    "\n",
    "데이터셋을 캐싱할 때, `cache` 이전의 변환(파일 열기, 읽기 등)들은 첫 번째 에폭에서만 수행됩니다. 다음 에폭에서는 `cache` 변환에서 캐시된 데이터를 재사용합니다.<br><br>\n",
    "만약 사용자 정의 함수를 `map`을 사용해 적용하는 소요 비용이 높은 경우 로컬 저장소나 메모리에 데이터셋이 적재될 수 있다면, `map` 적용 이후에 `cache`를 적용하면 됩니다.<br>\n",
    "만약 사용자 정의 함수가 데이터 셋의 크기를 증가시켜 저장할 수 있는 공간을 넘어선다면, `cache` 이후에 `map` 함수를 적용해야합니다. <br>\n",
    "또는, 학습 작업을 수행하기 전 자원의 낭비를 줄이기 위해 먼저 전처리 작업을 수행하도록 고려하는 것이 좋습니다.<br><br>\n",
    "\n",
    "### 매핑 백터화\n",
    "`map` 변환으로 사용자 정의 함수를 호출하게되면, 사용자 정의 함수를 수행하고 스케쥴링하는 것에 관련된 오버헤드가 발생할 수 있습니다.<br>\n",
    "그래서 사용자 정의 함수를 벡터화하는 것(입력 배치에서 단 한번 연산됩니다.)이 좋습니다. 그리고 `batcch` 변환을 `map` 변환 이전에 적용해야합니다.<br><br>\n",
    "좋은 예제를 살펴보기에는 인공적으로 만든 데이터셋은 적절하지 않습니다. 스케줄링 딜레이가 10 마이크로 초 근처이므로, 인공 데이터셋에 사용된 수십 밀리 초보다 훨씬 짧으므로 영향을 살펴보기 어렵습니다.<br><br>\n",
    "`tf.data.Dataset.range` 함수를 사용하고, 학습 루프를 가장 간단한 형태로 간소화한 예제를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_dataset = tf.data.Dataset.range(10000)\n",
    "\n",
    "def fast_benchmark(dataset, num_epochs=2):\n",
    "    start_time = time.perf_counter()\n",
    "    for _ in tf.data.Dataset.range(num_epochs):\n",
    "        for _ in dataset:\n",
    "            pass\n",
    "    tf.print('Execution time', time.perf_counter() - start_time)\n",
    "\n",
    "def increment(x):\n",
    "    return x+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 스칼라 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time 0.6366476609837264\n"
     ]
    }
   ],
   "source": [
    "fast_benchmark(\n",
    "    fast_dataset\n",
    "    # 1개의 아이템에 한 번씩 함수를 적용합니다.\n",
    "    .map(increment)\n",
    "    # 배치\n",
    "    .batch(256)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://www.tensorflow.org/guide/images/data_performance/scalar_map.svg />\n",
    "\n",
    "해당 플랏은 어떤식으로 진행되는지 보여줍니다. 맵 함수가 각 샘플에 대해 적용되어진 것을 살펴볼 수 있습니다.<br>\n",
    "함수가 매우 빠른 반면에, 시간 성능에 대해 많은 오버헤드가 영향을 끼첬음을 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 벡터화된 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time 0.029602861002786085\n"
     ]
    }
   ],
   "source": [
    "fast_benchmark(\n",
    "    fast_dataset\n",
    "    .batch(256)\n",
    "    # 한 번의 배치에 함수를 적용\n",
    "    # tf.Tensor.__add__ 메소드는 이미 배치를 적용했습니다.\n",
    "    .map(increment)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://www.tensorflow.org/guide/images/data_performance/vectorized_map.svg />\n",
    "\n",
    "이번에는 맵 함수가 한번 호출되었습니다. 그리고 샘플의 배치에 대해 적용되었습니다. <br>\n",
    "함수 수행에 더 많은 시간이 소요되었지만, 오버헤드는 단 한번 발생하였으므로 전체 시간 성능의 향상을 확인할 수 있습니다.<br><br>\n",
    "\n",
    "### 메모리 사용량을 줄이는 방법\n",
    "`interleave`, `prefetch` 그리고 `shuffle` 을 포함한 변환의 수는 원소의 내부 버퍼에 유지됩니다.<br>\n",
    "만약 사용자 정의 함수가 `map` 변환을 지날 때 원소의 크기가 변한다면, 맵 변환과 원소를 버퍼링 하는 변환들의 순서가 메모리 사용량에 영향을 끼칠 수 있습니다.<br>\n",
    "일반적으로, 다른 순서로 수행하는 것이 이상적인 성능을 갖더라도 적은 메모리 사용량을 갖는 순서를 선택하도록 합니다. <br><br>\n",
    "\n",
    "#### 부분적인 계산량 캐싱하기\n",
    "`map` 변환이 메모리 내에서 너무 큰 데이터를 생성하지 않는다면 해당 변환 이후에 데이터셋을 캐싱하는 것이 좋습니다. <br>\n",
    "매핑 함수는 시간 소모 또는 메모리 소모의 관점에서 2가지로 나뉠 수 있고, 이는 트레이드 오프 관계입니다. <br>\n",
    "이 경우, 변환을 다음과 같이 수행할 수 있습니다.\n",
    "\n",
    "> dataset.map(time_consuming_mapping).cache().map(memory_consuming_mapping)\n",
    "\n",
    "이제 시간이 오래 소요되는 연산은 첫 에폭에서 수행하고, 캐싱에 많은 메모리 사용을 피할 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kyle",
   "language": "python",
   "name": "kyle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
