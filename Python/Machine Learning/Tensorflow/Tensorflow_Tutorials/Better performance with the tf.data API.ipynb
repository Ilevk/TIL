{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.data API를 사용한 더 나은 성능\n",
    "##### url: https://www.tensorflow.org/guide/data_performance?hl=en#overview\n",
    "\n",
    "- 목차\n",
    "    - 개요\n",
    "    - 자원\n",
    "    - 설정\n",
    "        - 데이터셋\n",
    "        - 학습 루프\n",
    "    - 성능 최적화\n",
    "        - 간단한 접근법\n",
    "        - 프리페칭\n",
    "        - 데이터 추출 병렬화\n",
    "        - 데이터 변환 병렬화\n",
    "        - 캐싱\n",
    "        - 매핑 함수 벡터화하기\n",
    "        - 메모리 사용 흔적 줄이기\n",
    "    - 모범 사례 요약\n",
    "## 개요\n",
    "GPU들과 TPU들은 단일 훈련 스탭을 수행하기 위한 소요 시간을 급격히 줄일 수 있습니다. <br>\n",
    "최고 성능을 달성하는 것은 현재 스텝이 끝나기 전에 다음 스텝의 데이터를 운반하는 효율적인 입력 파이프라인이 요구됩니다.<br>\n",
    "`tf.data` API는 유연하고, 효율적인 입력 파이프라인을 생성하는 것을 도와줍니다.<br>\n",
    "해당 문서는 매우 성능이 좋은 텐서플로우 입력 파이프라인을 생성하기 위해 `tf.data` API를 어떻게 사용하는지 보여줍니다.<br><br>다음으로 넘어가기 전에 `tf.data` API를 어떻게 사용하는지 배울 수 있는 \"[Build TensorFlot input pipelines](https://www.tensorflow.org/guide/data)\" 가이드를 읽어보세요.\n",
    "\n",
    "## 자원\n",
    "- [Build TensorFlot input pipelines](https://www.tensorflow.org/guide/data)\n",
    "- [`tf.data.Dataset'](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 가이드 전반에서, 반복적으로 데이터셋과 성능 측정을 할 예정입니다.<br>\n",
    "다른 인자에 의해, 동일한 성능의 벤치마크를 만드는 것은 어려울 수 있습니다.\n",
    "\n",
    "- 현재 CPU 로드율\n",
    "- 네트워크 트래픽\n",
    "- 캐시 같은 복잡한 매카니즘 등\n",
    "\n",
    "동일한 성능의 벤치마크를 제공하기 위해 인공적으로 예제를 만들겠습니다.\n",
    "\n",
    "### 데이터 셋\n",
    "`tf.data.Dataset`를 상속 받은 `ArtificialDataset` 클래스를 정의합니다.<br>\n",
    "해당 데이터셋은 다음과 같은 특징을 갖습니다.\n",
    "\n",
    "- `num_samples` 만큼의 샘플을 생성합니다. (기본값 3)\n",
    "- 파일을 열고 첫 번째 항목을 읽기 전에 잠시 대기합니다.\n",
    "- 파일에서 데이터를 읽어와 각 아이템을 반환할 때마다 잠시 대기합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtificialDataset(tf.data.Dataset):\n",
    "    def _generator(num_samples):\n",
    "        # 파일 열기\n",
    "        time.sleep(0.03)\n",
    "        \n",
    "        for sample_idx in range(num_samples):\n",
    "            # 파일로부터 (line, record)로 이루어진 데이터를 읽습니다.\n",
    "            time.sleep(0.015)\n",
    "            \n",
    "            yield (sample_idx, )\n",
    "    \n",
    "    def __new__(cls, num_samples=3):\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            cls._generator,\n",
    "            output_types=tf.dtypes.int64,\n",
    "            output_shapes=(1,),\n",
    "            args=(num_samples,)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 데이터셋은 `tf.data.Datast.range`와 비슷하지만, 각 샘플의 시작과 사이에 고정된 딜레이가 추가되었습니다.\n",
    "\n",
    "### 학습 루프\n",
    "전반에 걸쳐 데이터셋을 반복하는 것이 얼마나 오래걸리는지 측정하기 위해 더미 학습 루프를 작성해야합니다.<br>\n",
    "학습 시간을 시뮬레이팅 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(dataset, num_epochs=2):\n",
    "    start_time = time.perf_counter()\n",
    "    for epoch_num in range(num_epochs):\n",
    "        for sample in dataset:\n",
    "            # 학습을 수행 하는 단계\n",
    "            time.sleep(0.01)\n",
    "    tf.print('수행 시간: ', time.perf_counter() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능 최적화하기\n",
    "어떻게 성능이 최적화될 수 있는지 보여주기 위해서, `ArtificialDataset`의 성능을 개선해야 합니다.\n",
    "\n",
    "### 간단한 접근 방법\n",
    "트릭을 사용하지 않고 간단한 파이프라인으로 시작해봅시다. 현재 데이터셋은 다음과 같이 반복됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수행 시간:  0.2771796619927045\n"
     ]
    }
   ],
   "source": [
    "benchmark(ArtificialDataset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같이, 수행 시간이 어떻게 소비되었는지 볼 수 있습니다.\n",
    "\n",
    "<img src=https://www.tensorflow.org/guide/images/data_performance/naive.svg />\n",
    "\n",
    "학습 단계를 수행하는 것은 다음을 포함합니다. \n",
    "- 파일이 열리지 않았다면, 파일을 연다.\n",
    "- 데이터 엔트리를 파일로부터 불러온다.\n",
    "- 학습을 위해 데이터를 사용한다.\n",
    "\n",
    "이와 같이 간단하게 동기화된 구현에서 모델은 파이프라인이 데이터를 파일로부터 불러오는 동안 유휴(idle) 상태에 있게 됩니다.<br>\n",
    "반대로 모델이 학습하는 동안 입력 파이프라인은 유휴 상태에 있게 됩니다.<br>\n",
    "이와 같이 학습 단계의 소요 시간은 파일 열기, 데이터 불러오기, 학습 시간의 합으로 이루어집니다.<br><br>\n",
    "다음 섹션에서는 입력 파이프라인을 구축하고, 성능이 뛰어난 텐서플로우 입력 파이프라인 설계의 모범 사례를 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프리페치(Prefetching)\n",
    "프리페치는 학습 단계에서 모델 수행 및 전처리와 동시에 수앻됩니다. `s`번째 학습 단계에서 모델이 수행되는 동안, 입력 파이프라인은 `s+1`번째 데이터를 미리 읽습니다. <br>\n",
    "이러한 방법으로 학습에 소요되는 시간과 데이터를 추출하기 위해 소요되는 시간을 최대한 줄일 수 있습니다.<br><br>\n",
    "`tf.data` API는 `tf.data.Dataset.prefetch` 변환을 제공합니다. 해당 함수는 데이터를 소비하는 시간과 데이터를 생성하는 시간을 분리하는 작업에 사용될 수 있습니다.<br>\n",
    "특히, 해당 함수는 백그라운드 스레드와 데이터가 요청되기 이전에 입력 데이터셋으로부터 원소를 프리페치하기 위한 내부 버퍼를 사용합니다.<br>\n",
    "프리페치 될 원소의 수는 한번의 학습 단계에서 사용될 배치의 크기만큼이(또는 가능한 더 크게) 되어야 합니다.<br>\n",
    "이러한 값을 수동으로 지정할 수 있거나 수행 중 동적으로 값을 튜닝하는 `tf.data` 런타임을 수행할 `tf.data.experimental.AUTOTUNE`으로 설정할 수 있습니다.<br><br>\n",
    "프리페치 변환은 'Producer' 작업과 'Consumer' 작업이 겹칠 때마다 시간적 이익을 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수행 시간:  0.21492886697524227\n"
     ]
    }
   ],
   "source": [
    "benchmark(\n",
    "    ArtificialDataset()\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://www.tensorflow.org/guide/images/data_performance/prefetched.svg />\n",
    "샘플 0에 대한 학습이 수행되는 동안에 입력 파이프라인이 샘플 1의 데이터를 읽고 있는 것을 확인할 수 있습니다. 당연히 그 다음도 동일하게 이어집니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kyle",
   "language": "python",
   "name": "kyle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
